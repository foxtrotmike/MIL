{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "milgen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/foxtrotmike/MIL/blob/master/milgen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCZMHTUcgSeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "11f85248-aafa-47eb-b965-ce24f4252265"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Dec 17 01:47:34 2019\n",
        "How to do MIL when the bag just won't fit into memory: Use hill climbing search\n",
        "This should require significantly less number of bags in comparison to the Fuchs paper\n",
        "(https://arxiv.org/abs/1805.06983)\n",
        "Idea:\n",
        "In each iteration\n",
        "  Load random patches (examples) from a bag\n",
        "  Append to it, the last max scoring example of the bag\n",
        "  Save max scoring example of the bag to file\n",
        "  Do the above for a randomly chosen positive and a random negative bag\n",
        "  Compute loss\n",
        "  Backpropagate\n",
        "Based on: https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
        "@author: Fayyaz Minhas\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "class MILDataset(data.Dataset):\n",
        "  'Characterizes a Multiple Instance dataset for PyTorch'\n",
        "  def __init__(self, list_IDs, labels, maxsize = None):\n",
        "        'Initialization'\n",
        "        self.labels = labels #dictionary of id to label\n",
        "        self.list_IDs = list_IDs #list of ids\n",
        "        self.maxsize = maxsize #max size to load at once\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.list_IDs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        ID = self.list_IDs[index]\n",
        "        if self.maxsize is None:\n",
        "          maxsize = 10\n",
        "        else:\n",
        "          maxsize = self.maxsize\n",
        "        #Load random examples (patches) from bag file (WSI) based on ID   \n",
        "        # Preferably a fast mechanism of loading random patches\n",
        "        X = np.random.rand(maxsize,2) #temporary random data\n",
        "        # load the top scoring patch (example) for this id if it exists\n",
        "        #xtop = load('data/' + ID + '.top')\n",
        "        xtop = np.random.rand(1,2) #temporary random data\n",
        "        # can do data augmentation as well if required here\n",
        "        X = np.vstack((X,xtop))\n",
        "        y = self.labels[ID]\n",
        "        return X,ID,y\n",
        "    \n",
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "#cudnn.benchmark = True\n",
        "max_iters = 10 #ensure that each bag is selected multiple times\n",
        "# Datasets\n",
        "partition = {'pos': ['id-1', 'id-2', 'id-3'], 'neg': ['id-4','id-5']}# IDs (bag ids or WSI names)\n",
        "labels = dict([(k,1.0) for k in partition['pos']]+[(k,-1.0) for k in partition['neg']]) \n",
        "# Generators (for positive and negative bags)\n",
        "posgen = data.DataLoader(MILDataset(partition['pos'], labels), pin_memory = True, shuffle = True)\n",
        "neggen = data.DataLoader(MILDataset(partition['neg'], labels), pin_memory = True, shuffle = True)\n",
        "positer, negiter = iter(posgen), iter(neggen)\n",
        "# Loop over epochs\n",
        "for i in range(max_iters):\n",
        "  # Selecting a positive and a negative bag randomly\n",
        "    try: #not pretty but works!\n",
        "      PX,Pid,_ = next(positer)\n",
        "    except StopIteration:\n",
        "      positer = iter(posgen)\n",
        "      PX,Pid,_ = next(positer)\n",
        "    PX,Pid = PX[0].to(device),Pid[0]\n",
        "    try:\n",
        "      NX,Nid,_ = next(negiter)\n",
        "    except StopIteration:\n",
        "      negiter = iter(neggen)\n",
        "      NX,Ni,_ = next(negiter)\n",
        "    NX,Nid = NX[0].to(device),Nid[0]\n",
        "    print(i,Pid,Nid)\n",
        "  # TODO: compute score over PX and NX. Save top scoring patch of each to a file\n",
        "    # so it can be loaded\n",
        "  # TODO: Comput loss and backpropagate"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 id-1 id-5\n",
            "1 id-3 id-4\n",
            "2 id-2 i\n",
            "3 id-3 id-5\n",
            "4 id-2 i\n",
            "5 id-1 id-5\n",
            "6 id-2 i\n",
            "7 id-1 id-5\n",
            "8 id-3 i\n",
            "9 id-3 id-4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3l-zd7_8tVz",
        "colab_type": "text"
      },
      "source": [
        "This approach is losely based on the following algorithm for random search for the max element in an array (Hill Climbing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVRh3RdY7OHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59624c36-db8f-4482-de2b-0ea4258f356d"
      },
      "source": [
        "Z = np.random.rand(100)\n",
        "M = -np.inf\n",
        "for _ in range(10):\n",
        "  m = np.max(np.random.choice(Z,5))\n",
        "  if m>M:\n",
        "    M = m\n",
        "print(\"Max Found through Random Search:\",M,\"Actual Max:\",np.max(Z))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Found through Random Search: 0.927732556797191 Actual Max: 0.9986497246288282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znEoWIVw7SLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}