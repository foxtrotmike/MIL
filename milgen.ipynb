{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "milgen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/foxtrotmike/MIL/blob/master/milgen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCZMHTUcgSeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "11f85248-aafa-47eb-b965-ce24f4252265"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Dec 17 01:47:34 2019\n",
        "How to do MIL when the bag just won't fit into memory\n",
        "Idea:\n",
        "In each iteration\n",
        "  Load random patches (examples) from a bag\n",
        "  Append to it, the last max scoring example of the bag\n",
        "  Save max scoring example of the bag to file\n",
        "  Do the above for a randomly chosen positive and a random negative bag\n",
        "  Compute loss\n",
        "  Backpropagate\n",
        "Based on: https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
        "@author: Fayyaz Minhas\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "class MILDataset(data.Dataset):\n",
        "  'Characterizes a Multiple Instance dataset for PyTorch'\n",
        "  def __init__(self, list_IDs, labels, maxsize = None):\n",
        "        'Initialization'\n",
        "        self.labels = labels #dictionary of id to label\n",
        "        self.list_IDs = list_IDs #list of ids\n",
        "        self.maxsize = maxsize #max size to load at once\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.list_IDs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        ID = self.list_IDs[index]\n",
        "        if self.maxsize is None:\n",
        "          maxsize = 10\n",
        "        else:\n",
        "          maxsize = self.maxsize\n",
        "        #Load random examples (patches) from bag file (WSI) based on ID   \n",
        "        # Preferably a fast mechanism of loading random patches\n",
        "        X = np.random.rand(maxsize,2) #temporary random data\n",
        "        # load the top scoring patch (example) for this id if it exists\n",
        "        #xtop = load('data/' + ID + '.top')\n",
        "        xtop = np.random.rand(1,2) #temporary random data\n",
        "        # can do data augmentation as well if required here\n",
        "        X = np.vstack((X,xtop))\n",
        "        y = self.labels[ID]\n",
        "        return X,ID,y\n",
        "    \n",
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "#cudnn.benchmark = True\n",
        "max_iters = 10 #ensure that each bag is selected multiple times\n",
        "# Datasets\n",
        "partition = {'pos': ['id-1', 'id-2', 'id-3'], 'neg': ['id-4','id-5']}# IDs (bag ids or WSI names)\n",
        "labels = dict([(k,1.0) for k in partition['pos']]+[(k,-1.0) for k in partition['neg']]) \n",
        "# Generators (for positive and negative bags)\n",
        "posgen = data.DataLoader(MILDataset(partition['pos'], labels), pin_memory = True, shuffle = True)\n",
        "neggen = data.DataLoader(MILDataset(partition['neg'], labels), pin_memory = True, shuffle = True)\n",
        "positer, negiter = iter(posgen), iter(neggen)\n",
        "# Loop over epochs\n",
        "for i in range(max_iters):\n",
        "    try: #not pretty but works!\n",
        "      PX,Pid,_ = next(positer)\n",
        "    except StopIteration:\n",
        "      positer = iter(posgen)\n",
        "      PX,Pid,_ = next(positer)\n",
        "    PX,Pid = PX[0].to(device),Pid[0]\n",
        "    try:\n",
        "      NX,Nid,_ = next(negiter)\n",
        "    except StopIteration:\n",
        "      negiter = iter(neggen)\n",
        "      NX,Ni,_ = next(negiter)\n",
        "    NX,Nid = NX[0].to(device),Nid[0]\n",
        "    print(i,Pid,Nid)\n",
        "    # compute score over PX and NX. Save top scoring patch of each to a file\n",
        "    # so it can be loaded\n",
        "    # Comput loss "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 id-1 id-5\n",
            "1 id-3 id-4\n",
            "2 id-2 i\n",
            "3 id-3 id-5\n",
            "4 id-2 i\n",
            "5 id-1 id-5\n",
            "6 id-2 i\n",
            "7 id-1 id-5\n",
            "8 id-3 i\n",
            "9 id-3 id-4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9brS199gWRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "f060cb63-c15b-4fb1-d03d-94a425c5df02"
      },
      "source": [
        "PX"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4601, 0.4991],\n",
              "        [0.1672, 0.3796],\n",
              "        [0.9596, 0.7124],\n",
              "        [0.7853, 0.6906],\n",
              "        [0.8232, 0.8574],\n",
              "        [0.1193, 0.2484],\n",
              "        [0.2003, 0.5079],\n",
              "        [0.6945, 0.4801],\n",
              "        [0.6093, 0.5968],\n",
              "        [0.3975, 0.3490]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzGQfaaql4Hb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "591d5f3b-c342-4f22-925e-db4a59d765bf"
      },
      "source": [
        "local_labels"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaO237PrmCj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}